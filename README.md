# EfficientAI-MLX-Toolkit

ğŸš€ **Apple Silicon optimized AI toolkit for efficient machine learning workflows**

A comprehensive toolkit designed specifically for Apple Silicon (M1/M2/M3) that provides optimized implementations of various AI/ML techniques including LoRA fine-tuning, quantization, model compression, and deployment utilities.

## âœ¨ Features

- **ğŸ Apple Silicon Optimized**: Native MLX framework integration with MPS and ANE support
- **ğŸ› ï¸ Shared Utilities**: Production-ready logging, configuration, benchmarking, and file operations
- **ğŸ“Š Comprehensive Benchmarking**: Hardware-aware performance measurement and comparison
- **âš™ï¸ Advanced Configuration**: Profile-based config with environment overrides and validation
- **ğŸ”§ Development Tools**: CLI toolkit for setup, benchmarking, and system information

## ğŸ—ï¸ Architecture

```
EfficientAI-MLX-Toolkit/
â”œâ”€â”€ utils/                     # âœ… Complete shared utilities
â”‚   â”œâ”€â”€ logging_utils.py       # Apple Silicon tracking & log management
â”‚   â”œâ”€â”€ config_manager.py      # Multi-format config with profiles
â”‚   â”œâ”€â”€ file_operations.py     # Safe file ops with backup support
â”‚   â”œâ”€â”€ benchmark_runner.py    # Hardware-aware benchmarking
â”‚   â””â”€â”€ plotting_utils.py      # Visualization and reporting
â”œâ”€â”€ efficientai_mlx_toolkit/   # ğŸš§ Basic CLI (needs expansion)
â”œâ”€â”€ dspy_toolkit/              # âœ… Complete DSPy integration framework
â”œâ”€â”€ knowledge_base/            # âœ… Complete development knowledge system
â”œâ”€â”€ environment/               # ğŸš§ Environment setup utilities
â””â”€â”€ projects/                  # ğŸš§ Individual ML project implementations
```

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/Mathews-Tom/EfficientAI-MLX-Toolkit.git
cd EfficientAI-MLX-Toolkit

# Install with uv (recommended)
uv sync

# Or install with pip
pip install -e .
```

### Basic Usage

```bash
# System information and hardware detection
uv run efficientai-toolkit info

# Environment setup for Apple Silicon
uv run efficientai-toolkit setup

# Run benchmarks
uv run efficientai-toolkit benchmark
```

### Using Shared Utilities

```python
from utils import setup_logging, ConfigManager, BenchmarkRunner
from pathlib import Path

# Setup Apple Silicon optimized logging
setup_logging(
    log_level="INFO",
    log_file=Path("logs/app.log"),
    enable_apple_silicon_tracking=True
)

# Configuration with profiles
config = ConfigManager(Path("config.yaml"), profile="development")
debug_mode = config.get_with_type("debug", bool, default=False)

# Hardware-aware benchmarking
runner = BenchmarkRunner()
if runner.hardware_info.mlx_available:
    result = runner.run_benchmark("my_optimization", benchmark_func)
```

## ğŸ“‹ Project Status

| Component | Status | Description |
|-----------|--------|-------------|
| **Shared Utilities** | âœ… **Complete** | Production-ready foundational utilities |
| **DSPy Toolkit Framework** | âœ… **Complete** | Structured AI workflows with MLX backend |
| **Knowledge Base System** | âœ… **Complete** | Development knowledge management |
| **EfficientAI CLI** | ğŸš§ **Basic** | Core CLI exists, advanced features planned |
| **LoRA Fine-tuning MLX** | ğŸ“‹ **Planned** | Next priority implementation |
| **Model Compression** | ğŸ“‹ **Planned** | Quantization and pruning pipelines |
| **Deployment Tools** | ğŸ“‹ **Planned** | FastAPI, Gradio, containerization |

## ğŸ§ª Development

### Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov

# Run specific test categories
uv run pytest -m "not slow"           # Exclude slow tests
uv run pytest -m apple_silicon        # Apple Silicon specific tests
```

### Code Quality

```bash
# Format code
uv run black .

# Lint code
uv run ruff check .

# Type checking
uv run mypy .

# All quality checks
uv run black . && uv run isort . && uv run ruff check . && uv run mypy .
```

## ğŸ¯ Planned Features

### ğŸ”„ In Development

- **LoRA Fine-tuning MLX**: Apple Silicon optimized LoRA implementation
- **Quantized Model Benchmarks**: 4-bit/8-bit quantization with MLX
- **Model Compression Pipeline**: Pruning and distillation for CPU deployment

### ğŸ“… Roadmap

- **Multimodal CLIP Fine-tuning**: Vision-language model optimization
- **Core ML Diffusion**: Stable Diffusion for Apple Neural Engine
- **Federated Learning System**: Distributed training across Apple devices
- **MLOps Integration**: Complete deployment and monitoring solutions

## ğŸ“š Documentation

- **[CLAUDE.md](CLAUDE.md)**: Developer guidance and architecture overview
- **[Development Knowledge Base](knowledge_base/)**: Comprehensive documentation system
- **[Project Specifications](.kiro/specs/)**: Detailed implementation plans
- **[API Documentation](docs/)**: Generated API documentation

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create feature branch**: `git checkout -b feature/your-feature`
3. **Follow development guidelines** in [CLAUDE.md](CLAUDE.md)
4. **Add comprehensive tests** for new functionality
5. **Submit pull request** with detailed description

### Development Guidelines

- **Use `uv` for package management**: All dependencies and commands
- **Apple Silicon first**: Optimize for M1/M2/M3 hardware
- **Pathlib everywhere**: Modern file handling patterns
- **Comprehensive testing**: Maintain high test coverage
- **Type safety**: Full type annotations required

## ğŸ”§ System Requirements

### Recommended (Apple Silicon)

- **macOS 12.0+** with Apple Silicon (M1/M2/M3)
- **Python 3.12+**
- **MLX framework** for optimal performance
- **16GB+ RAM** for model training/inference

### Supported

- **macOS/Linux/Windows** with fallback implementations
- **Intel/AMD processors** with CPU optimizations
- **CUDA GPUs** with PyTorch backend

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Apple MLX Team**: For the excellent MLX framework
- **DSPy Framework**: For structured AI programming patterns
- **Open Source Community**: For the tools and libraries that make this possible

---

**Built with â¤ï¸ for Apple Silicon â€¢ Optimized for the future of AI**
